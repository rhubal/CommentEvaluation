{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2022-2023 RENCI/ESoP, Chapel Hill, NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd437a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as sia\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows as df2r\n",
    "\n",
    "pd.options.mode.chained_assignment = None # suppress warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53200885",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = []\n",
    "neg_list = []\n",
    "neut_list = []\n",
    "\n",
    "pos_weight = []\n",
    "neg_weight = []\n",
    "neut_weight = 0\n",
    "\n",
    "def load_dictionaries():\n",
    "\n",
    "    pos_words1 = pd.read_table('dictionaries/green terminology.txt', header=None)\n",
    "    neg_words1 = pd.read_table('dictionaries/red terminology.txt', header=None)\n",
    "    neut_words = pd.read_table('dictionaries/white terminology.txt', header=None)\n",
    "\n",
    "    pos_words2 = pd.read_table('dictionaries/green terminology from literature.txt', header=None)\n",
    "    neg_words2 = pd.read_table('dictionaries/red terminology from literature.txt', header=None)\n",
    "\n",
    "    pos_words = pd.concat([pos_words1, pos_words2]).drop_duplicates()\n",
    "    neg_words = pd.concat([neg_words1, neg_words2]).drop_duplicates()\n",
    "\n",
    "    for i in range(0, len(pos_words)):\n",
    "        if pos_words.iloc[i, 1] != 0: # ignore entries with zero weight\n",
    "            pos_list.append(pos_words.iloc[i, 0])\n",
    "            pos_weight.append(pos_words.iloc[i, 1])\n",
    "\n",
    "    for i in range(0, len(neg_words)):\n",
    "        if neg_words.iloc[i, 1] != 0:\n",
    "            neg_list.append(neg_words.iloc[i, 0])\n",
    "            neg_weight.append(neg_words.iloc[i, 1])\n",
    "\n",
    "    for i in range(0, len(neut_words)):\n",
    "        neut_list.append(neut_words.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters():\n",
    "    with open(ipynbname.name() + '.config') as f: # expect config file name to match notebook name\n",
    "        for p in f:\n",
    "            exec(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80debdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dictionaries()\n",
    "load_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants; some employ parameters\n",
    "\n",
    "nltk.download(['names', 'stopwords', 'state_union', 'averaged_perceptron_tagger', 'vader_lexicon'], quiet=True)\n",
    "\n",
    "punct = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "sii = sia()\n",
    "\n",
    "comment_type = [approving, critical, additional]\n",
    "comment_weighting = [approving_weighting, critical_weighting, additional_weighting]\n",
    "\n",
    "very_pos_label = 'Very positive'\n",
    "very_neg_label = 'Very negative'\n",
    "pos_label = 'Positive'\n",
    "neg_label = 'Negative'\n",
    "neut_label = 'Neutral'\n",
    "\n",
    "very_pos_score = high_cut + e\n",
    "very_neg_score = -1 * very_pos_score\n",
    "pos_score = medium_cut + e\n",
    "neg_score = -1 * pos_score\n",
    "neut_score = 0\n",
    "\n",
    "n = np.nan\n",
    "nl = 'null'\n",
    "\n",
    "del high_cut\n",
    "del medium_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define additional constants for debugging/testing\n",
    "\n",
    "am_debugging = False\n",
    "using_test_data = False\n",
    "using_training_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "\n",
    "def biggest_val(l):\n",
    "    if len(l) == 0:\n",
    "        return None\n",
    "    elif len(l) == 1:\n",
    "        return l[0]\n",
    "    elif len(l) == 2:\n",
    "        if abs(l[0]) < abs(l[1]):\n",
    "            return l[1]\n",
    "        return l[0]\n",
    "    else:\n",
    "        return biggest_val([l[0], biggest_val(l[1:])])\n",
    "\n",
    "def clean_data(df, cols): # prepare comments for analysis\n",
    "    for j in cols:\n",
    "        for i in range(len(df)):\n",
    "            t = df.iloc[i, j]\n",
    "            if isinstance(t, str):\n",
    "                u = clear_punctuation(t.strip().lower())\n",
    "                if matches(u, 'na'):\n",
    "                    df.iloc[i, j] = None\n",
    "                else:\n",
    "                    df.iloc[i, j] = u\n",
    "            else:\n",
    "                df.iloc[i, j] = ''\n",
    "    return df\n",
    "\n",
    "def clean_filename(s):\n",
    "    f = ''.join(c for c in s.strip() if (c.isalnum() or c in '._- '))\n",
    "    return f\n",
    "\n",
    "def clean_vals(df, cols): # prepare numeric values for analysis\n",
    "    for j in cols:\n",
    "        for i in range(len(df)):\n",
    "            v = df.iloc[i, j]\n",
    "            try:\n",
    "                if v is not None:\n",
    "                    if not isinstance(v, int) and not isinstance(v, float) and not isinstance(v, complex):\n",
    "                        if isinstance(v, str):\n",
    "                            if v.isnumeric():\n",
    "                                df.iloc[i, j] = float(v)\n",
    "                            else:\n",
    "                                df.iloc[i, j] = None\n",
    "                        else:\n",
    "                            df.iloc[i, j] = None\n",
    "            except (TypeError, ValueError):\n",
    "                df.iloc[i, j] = None\n",
    "    return df\n",
    "\n",
    "def clear_if_starts_with_neut_comment(c): # an initial neutral comment may skew scores\n",
    "    for u in neut_list:\n",
    "        if c.startswith(u):\n",
    "            return c.replace(u, '')\n",
    "    return c\n",
    "\n",
    "def clear_punctuation(s):\n",
    "    for t in s:\n",
    "        if t in punct:\n",
    "            s = s.replace(t, '')\n",
    "    return s\n",
    "\n",
    "def eval_weighting(w):\n",
    "    if w <= very_neg_score:\n",
    "        return very_neg_label\n",
    "    elif w <= neg_score:\n",
    "        return neg_label\n",
    "    elif w >= very_pos_score:\n",
    "        return very_pos_label\n",
    "    elif w >= pos_score:\n",
    "        return pos_label\n",
    "    else:\n",
    "        return neut_label\n",
    "\n",
    "def get_col_index(df, s): # find which column holds a string\n",
    "    for h in list(df.columns):\n",
    "        if s in h:\n",
    "            return df.columns.get_loc(h)\n",
    "\n",
    "def get_lexical_semantic_score(s, t): # s is the comment, t an indicator of type of comment\n",
    "    s = clear_if_starts_with_neut_comment(s)\n",
    "    w = 0\n",
    "    for i, p in enumerate(pos_list):\n",
    "        if p in s:\n",
    "            c = np.cbrt(s.count(p)) # tamp down weight given to repetition\n",
    "            w = min(1, w + adjustment_value * pos_weight[i] * c * comment_weighting[t])\n",
    "            if am_debugging:\n",
    "                print(str(w) + ' pos ' + p)\n",
    "    for j, n in enumerate(neg_list):\n",
    "        if n in s:\n",
    "            c = np.sqrt(s.count(n))\n",
    "            w = max(-1, w - adjustment_value * neg_weight[j] * c * comment_weighting[t])\n",
    "            if am_debugging:\n",
    "                print(str(w) + ' neg ' + n)\n",
    "    return w\n",
    "\n",
    "def get_score(s, s_):\n",
    "    if is_very_neg_comment(s, s_):\n",
    "        return very_neg_score\n",
    "    elif is_neg_comment(s, s_):\n",
    "        return neg_score\n",
    "    elif is_very_pos_comment(s, s_):\n",
    "        return very_pos_score\n",
    "    elif is_pos_comment(s, s_):\n",
    "        return pos_score\n",
    "    else:\n",
    "        return neut_score\n",
    "\n",
    "def get_sentiment_score(s, t):\n",
    "    s = clear_if_starts_with_neut_comment(s)\n",
    "    d = .25 # temper scores as they tend to be high (range is +/-4)\n",
    "    return sii.polarity_scores(s)['compound'] * comment_weighting[t] * d\n",
    "\n",
    "def is_additional_comment(i):\n",
    "    if comment_type.index(additional) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_approving_comment(i):\n",
    "    if comment_type.index(approving) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_at_all_neg_comment(c, t):\n",
    "    if is_very_neg_comment(c, t):\n",
    "        return True\n",
    "    if is_neg_comment(c, t):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_at_all_neut_comment(c, t):\n",
    "    if is_neut_comment(c, t):\n",
    "        return True\n",
    "    for u in neut_list:\n",
    "        if u in c:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_at_all_pos_comment(c, t):\n",
    "    if is_very_pos_comment(c, t):\n",
    "        return True\n",
    "    if is_pos_comment(c, t):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_average_length_comment(c):\n",
    "    return not (is_lengthy_comment(c) or is_brief_comment(c))\n",
    "\n",
    "def is_brief_comment(c):\n",
    "    return (len(c.split()) < brief)\n",
    "\n",
    "def is_critical_comment(i):\n",
    "    if comment_type.index(critical) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_lengthy_comment(c):\n",
    "    return (len(c.split()) > lengthy)\n",
    "\n",
    "def is_neg_comment(c, t):\n",
    "    if is_neg_score(resolve([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neg_score(s):\n",
    "    if matches(eval_weighting(s), neg_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neut_comment(c, t):\n",
    "    for u in neut_list:\n",
    "        if matches(u, c):\n",
    "            return True\n",
    "    if is_neut_score(resolve([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neut_score(s):\n",
    "    if matches(eval_weighting(s), neut_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_overlong_comment(c):\n",
    "    return (len(c.split()) > overlong)\n",
    "\n",
    "def is_pos_comment(c, t):\n",
    "    if is_pos_score(resolve([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_pos_score(s):\n",
    "    if matches(eval_weighting(s), pos_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_neg_comment(c, t):\n",
    "    if is_very_pos_score(get_lexical_semantic_score(c, t)):\n",
    "        pass # still, conservatively, can be very negative depending on NLP\n",
    "    if is_very_neg_score(resolve([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_neg_score(s):\n",
    "    if matches(eval_weighting(s), very_neg_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_pos_comment(c, t):\n",
    "    if is_very_neg_score(get_lexical_semantic_score(c, t)):\n",
    "        return False # just cannot be very positive even if NLP is 'fooled'\n",
    "    if is_very_pos_score(resolve([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_pos_score(s):\n",
    "    if matches(eval_weighting(s), very_pos_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def matches(s, t):\n",
    "    if s.strip().lower() == t.strip().lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def resolve(l):\n",
    "    if len(l) < 2:\n",
    "        return biggest_val(l)\n",
    "    elif len(l) == 2:\n",
    "        if valence(l[0]) == valence(l[1]) or valence(l[0]) == neut_score or valence(l[1]) == neut_score:\n",
    "            return biggest_val(l)\n",
    "        else:\n",
    "            return neut_score # two scores disagree\n",
    "    else:\n",
    "        return resolve([l[0], resolve(l[1:])])\n",
    "\n",
    "def valence(n):\n",
    "    if n > 0:\n",
    "        return pos_score\n",
    "    elif n < 0:\n",
    "        return neg_score\n",
    "    return neut_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose data file\n",
    "\n",
    "fc = FileChooser('data')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70081b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(fc.selected)\n",
    "cols_of_interest = []\n",
    "\n",
    "for i in range(0, len(comment_type)):\n",
    "    cols_of_interest.append(get_col_index(df, comment_type[i]))\n",
    "\n",
    "df = clean_data(df, cols_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_training_data:\n",
    "    cols_of_interest.append(get_col_index(df, 'Rating'))\n",
    "\n",
    "if using_test_data:\n",
    "    cols_of_interest.append(get_col_index(df, 'Quality of Interactions during Experience AVG'))\n",
    "    cols_of_interest.append(get_col_index(df, 'Quality of Preceptor/Preceptor Team AVG'))\n",
    "    cols_of_interest.append(get_col_index(df, 'Quality of Site AVG'))\n",
    "    df = clean_vals(df, cols_of_interest[-3:])\n",
    "\n",
    "df2 = df.iloc[:, cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of cases\n",
    "cases = []\n",
    "counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(c):\n",
    "\n",
    "    # consider, as needed, individually or in combination\n",
    "    #  lexical/syntactic\n",
    "    #  NL-based scores\n",
    "    #  lengths of approving, critical, and additional comments\n",
    "\n",
    "    a = ''\n",
    "    x = ''\n",
    "    d = ''\n",
    "\n",
    "    a_ = 0\n",
    "    x_ = 1\n",
    "    d_ = 2\n",
    "\n",
    "    al = []\n",
    "    xl = []\n",
    "    dl = []\n",
    "\n",
    "    for i in range(0, len(c)):\n",
    "        if is_approving_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                a = clear_punctuation(c[i])\n",
    "                a_ = i\n",
    "                al.append(get_lexical_semantic_score(a, a_))\n",
    "                al.append(get_sentiment_score(a, a_))\n",
    "        elif is_critical_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                x = clear_punctuation(c[i])\n",
    "                x_ = i\n",
    "                xl.append(get_lexical_semantic_score(x, x_))\n",
    "                xl.append(get_sentiment_score(x, x_))\n",
    "        elif is_additional_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                d = clear_punctuation(c[i])\n",
    "                d_ = i\n",
    "                dl.append(get_lexical_semantic_score(d, d_))\n",
    "                dl.append(get_sentiment_score(d, d_))\n",
    "\n",
    "    j = nl\n",
    "\n",
    "    # logic explained in logic/calculate_scores.xlsm\n",
    "\n",
    "    if is_overlong_comment(x) and is_at_all_neg_comment(x, x_):\n",
    "        j = 'n01'\n",
    "        r = very_neg_score\n",
    "\n",
    "    elif is_brief_comment(d) and is_very_neg_comment(d, d_):\n",
    "        j = 'n02'\n",
    "        r = get_score(d, d_) # very_neg_score\n",
    "\n",
    "    elif is_average_length_comment(a) and (is_overlong_comment(x + d) or (is_lengthy_comment(x) and is_lengthy_comment(d))) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n03'\n",
    "        r = very_neg_score\n",
    "\n",
    "    elif is_at_all_neut_comment(a, a_) and is_lengthy_comment(x) and is_at_all_neg_comment(x, x_) and is_neg_comment(d, d_):\n",
    "        j = 'n04'\n",
    "        r = very_neg_score\n",
    "\n",
    "    elif not is_brief_comment(a) and is_overlong_comment(x) and not is_lengthy_comment(d):\n",
    "        j = 'n05'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_brief_comment(a) and is_lengthy_comment(x) and is_lengthy_comment(d):\n",
    "        j = 'n06'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and is_at_all_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n07'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and (is_overlong_comment(x + d) or (is_lengthy_comment(x) and is_lengthy_comment(d))):\n",
    "        j = 'n08'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_pos_comment(a, a_) and is_brief_comment(a) and is_very_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n09'\n",
    "        r = get_score(d, d_) # very_neg_score or neg_score\n",
    "\n",
    "    elif not is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n10'\n",
    "        r = get_score(d, d_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_neut_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n11'\n",
    "        r = get_score(d, d_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and not is_at_all_pos_comment(d, d_):\n",
    "        j = 'n12'\n",
    "        r = get_score(x, x_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_at_all_neg_comment(a, a_) and (is_at_all_neg_comment(x, x_) or is_at_all_neg_comment(d, d_)):\n",
    "        j = 'n13'\n",
    "        r = get_score(a, a_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_neg_comment(a, a_) and (is_overlong_comment(a) or is_lengthy_comment(a)) and is_neut_comment(x, x_):\n",
    "        j = 'n14'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_brief_comment(x) and is_very_pos_comment(x, x_):\n",
    "        j = 'p02'\n",
    "        r = get_score(x, x_) # very_pos_score\n",
    "\n",
    "    elif is_average_length_comment(x) and (is_overlong_comment(a + d) or (is_lengthy_comment(a) and is_lengthy_comment(d))) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p03'\n",
    "        r = very_pos_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and is_at_all_pos_comment(a, a_) and is_at_all_neut_comment(x, x_) and is_pos_comment(d, d_):\n",
    "        j = 'p04'\n",
    "        r = very_pos_score\n",
    "\n",
    "    elif is_overlong_comment(a) and not is_brief_comment(x) and not is_lengthy_comment(d):\n",
    "        j = 'p05'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and is_brief_comment(x) and is_lengthy_comment(d):\n",
    "        j = 'p06'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_at_all_pos_comment(a, a_) and is_lengthy_comment(x) and is_at_all_neut_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p07'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_lengthy_comment(x) and (is_overlong_comment(a + d) or (is_lengthy_comment(a) and is_lengthy_comment(d))):\n",
    "        j = 'p08'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_very_pos_comment(a, a_) and is_neg_comment(x, x_) and is_brief_comment(x) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p09'\n",
    "        r = get_score(d, d_) # very_pos_score or pos_score\n",
    "\n",
    "    elif not is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p10'\n",
    "        r = get_score(d, d_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_neut_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p11'\n",
    "        r = get_score(d, d_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and not is_at_all_neg_comment(d, d_):\n",
    "        j = 'p12'\n",
    "        r = get_score(a, a_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_at_all_pos_comment(x, x_) and (is_at_all_pos_comment(a, a_) or is_at_all_pos_comment(d, d_)):\n",
    "        j = 'p13'\n",
    "        r = get_score(x, x_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_pos_comment(x, x_) and (is_overlong_comment(x) or is_lengthy_comment(x)) and is_neut_comment(a, a_):\n",
    "        j = 'p14'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_average_length_comment(a) and not is_lengthy_comment(x) and not is_lengthy_comment(d):\n",
    "\n",
    "        if not is_at_all_pos_comment(a, a_) and is_very_neg_comment(x, x_) and not is_at_all_pos_comment(d, d_):\n",
    "            j = 'n15'\n",
    "            r = get_score(x, x_) # very_neg_score\n",
    "\n",
    "        elif not is_at_all_pos_comment(a, a_) and is_neg_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n16'\n",
    "            r = get_score(d, d_) # very_neg_score\n",
    "\n",
    "        elif not is_at_all_pos_comment(a, a_) and not is_at_all_pos_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n17'\n",
    "            r = get_score(d, d_) # very_neg_score\n",
    "\n",
    "        elif is_at_all_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "            j = 'n18'\n",
    "            r = very_neg_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_very_neg_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n19'\n",
    "            r = neg_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "            j = 'n20'\n",
    "            r = neg_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and is_neut_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n21'\n",
    "            r = neg_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and is_very_neg_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'n22'\n",
    "            r = neg_score\n",
    "\n",
    "        elif not is_at_all_pos_comment(a, a_) and is_neg_comment(x, x_) and not is_at_all_pos_comment(d, d_):\n",
    "            j = 'n23'\n",
    "            r = get_score(x, x_) # neg_score\n",
    "\n",
    "        elif is_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'n24'\n",
    "            r = get_score(x, x_) # very_neg_score or neg_score\n",
    "\n",
    "        elif is_very_pos_comment(a, a_) and not is_at_all_neg_comment(x, x_) and not is_at_all_neg_comment(d, d_):\n",
    "            j = 'p15'\n",
    "            r = get_score(a, a_) # very_pos_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p16'\n",
    "            r = get_score(d, d_) # very_pos_score\n",
    "\n",
    "        elif not is_at_all_neg_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p17'\n",
    "            r = get_score(d, d_) # very_pos_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_at_all_neut_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "            j = 'p18'\n",
    "            r = very_pos_score\n",
    "\n",
    "        elif is_very_pos_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p19'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_neg_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "            j = 'p20'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_neut_comment(a, a_) and is_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p21'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_very_pos_comment(a, a_) and is_neg_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'p22'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and not is_at_all_neg_comment(x, x_) and not is_at_all_neg_comment(d, d_):\n",
    "            j = 'p23'\n",
    "            r = get_score(a, a_) # pos_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'p24'\n",
    "            r = get_score(a, a_) # very_pos_score or pos_score\n",
    "\n",
    "        elif is_neut_comment(a, a_) and is_neut_comment(x, x_):\n",
    "            j = '_99'\n",
    "            r = get_score(d, d_)\n",
    "\n",
    "    if matches(j, nl):\n",
    "        j = '_00'\n",
    "        r = neut_score # by default\n",
    "\n",
    "    if cases == []:\n",
    "        cases.append(j)\n",
    "        counts.append(1)\n",
    "    elif j in cases:\n",
    "        counts[cases.index(j)] += 1\n",
    "    else:\n",
    "        cases.append(j)\n",
    "        counts.append(1)\n",
    "\n",
    "    return [r, resolve(al), resolve(xl), resolve(dl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores\n",
    "\n",
    "vals = []\n",
    "evals = []\n",
    "all_vals = []\n",
    "\n",
    "for i in range(0, len(df2)): # loop for every row\n",
    "    s = calculate_score(df2.iloc[i])\n",
    "    vals.append(s[0])\n",
    "    evals.append(eval_weighting(s[0])) # overall very negative, negative, neutral, positive, or very positive\n",
    "    all_vals.append(s[1:]) # calcs for all comment types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts of cases\n",
    "\n",
    "if am_debugging:\n",
    "    assignments = []\n",
    "    for i, j in enumerate(cases):\n",
    "        assignments.append(j + ': ' + str(counts[i]))\n",
    "    print(assignments)\n",
    "\n",
    "del cases\n",
    "del counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_training_data or using_test_data:\n",
    "    f = input('What is the name of the output file? ')\n",
    "    f = clean_filename(f)\n",
    "else:\n",
    "    f = clean_filename(fc.selected_filename + '_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb406d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_test_data:\n",
    "    df2['Overall Quality'] = df.iloc[:, cols_of_interest[-3:]].mean(axis=1, skipna=True)\n",
    "    df2[df2['Overall Quality'].eq('')] = n # may be missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea606113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scores to file\n",
    "\n",
    "for i in range(0, len(comment_type)):\n",
    "    df2['Lexical/Semantic Valuation--' + comment_type[i].lower()] = [v[i] for v in all_vals]\n",
    "\n",
    "df2['Overall Valuation'] = vals\n",
    "df2['Overall Evaluation'] = evals\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "rows = df2r(df2, index=False)\n",
    "\n",
    "for i, row in enumerate(rows, 1):\n",
    "    for j, val in enumerate(row, 1):\n",
    "         wb.active.cell(row=i, column=j, value=val)\n",
    "\n",
    "wb.save('data/' + f + '.xlsx')\n",
    "\n",
    "del rows\n",
    "del wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging cell\n",
    "\n",
    "load_dictionaries() # reload in case any changes\n",
    "cases = []\n",
    "counts = []\n",
    "\n",
    "am_debugging = True\n",
    "\n",
    "a = 'strengths column'\n",
    "x = 'weaknesses column'\n",
    "d = 'additional comments column'\n",
    "\n",
    "s = calculate_score([a, x, d])\n",
    "\n",
    "print ('[' + eval_weighting(s[0]) + ', a:' + str(s[1]) + ', x:' + str(s[2]) + ', d:' + str(s[3]) + '] case: ' + cases[0])\n",
    "\n",
    "#eval_weighting(get_score(a, 0))\n",
    "#eval_weighting(get_score(x, 1))\n",
    "#eval_weighting(get_score(d, 2))\n",
    "#get_lexical_semantic_score(a, 0)\n",
    "#get_score(a, 0)\n",
    "#get_sentiment_score(a, 0)\n",
    "#is_at_all_pos_comment(a, 0)\n",
    "#is_at_all_neg_comment(a, 0)\n",
    "#is_neut_comment(a, 0)\n",
    "#is_very_pos_comment(a, 0)\n",
    "\n",
    "am_debugging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc37ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
