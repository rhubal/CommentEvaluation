{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd437a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as sia\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows as df2r\n",
    "\n",
    "pd.options.mode.chained_assignment = None # suppress warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53200885",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = pd.read_table('dictionaries/green terminology.txt', header=None)\n",
    "neg_words = pd.read_table('dictionaries/red terminology.txt', header=None)\n",
    "neut_words = pd.read_table('dictionaries/white terminology.txt', header=None)\n",
    "\n",
    "pos_list = []\n",
    "pos_weight = []\n",
    "for i in range(0, len(pos_words)):\n",
    "    if pos_words.iloc[i, 1] != 0: # ignore entries with zero weight\n",
    "        pos_list.append(pos_words.iloc[i, 0])\n",
    "        pos_weight.append(pos_words.iloc[i, 1])\n",
    "\n",
    "neg_list = []\n",
    "neg_weight = []\n",
    "for i in range(0, len(neg_words)):\n",
    "    if neg_words.iloc[i, 1] != 0:\n",
    "        neg_list.append(neg_words.iloc[i, 0])\n",
    "        neg_weight.append(neg_words.iloc[i, 1])\n",
    "\n",
    "neut_list = []\n",
    "neut_weight = 0\n",
    "for i in range(0, len(neut_words)):\n",
    "    neut_list.append(neut_words.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(['names', 'stopwords', 'state_union', 'averaged_perceptron_tagger', 'vader_lexicon'], quiet=True)\n",
    "\n",
    "punct = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "sii = sia()\n",
    "\n",
    "approving = 'strengths of this experience'\n",
    "critical = 'better learning experience'\n",
    "additional = 'Nothing further to add'\n",
    "\n",
    "comment_type = [approving, critical, additional]\n",
    "comment_weighting = [.975, .975, 1.05] # slightly overweight additional comments\n",
    "\n",
    "e = .001\n",
    "\n",
    "medium_cut = .05 # seems to be standard in literature for VADER compound score\n",
    "high_cut = .12 # guess at reasonable value\n",
    "adjustment_value = .04 + e # three net positive/negative statements imply high cutoff\n",
    "\n",
    "very_positive_label = 'Very positive'\n",
    "very_negative_label = 'Very negative'\n",
    "positive_label = 'Positive'\n",
    "negative_label = 'Negative'\n",
    "neutral_label = 'Neutral'\n",
    "\n",
    "very_positive_score = high_cut + e\n",
    "very_negative_score = -1 * very_positive_score\n",
    "positive_score = medium_cut + e\n",
    "negative_score = -1 * positive_score\n",
    "neutral_score = 0\n",
    "\n",
    "overlong = 300 # words\n",
    "lengthy = 150\n",
    "brief = 15\n",
    "\n",
    "n = numpy.nan\n",
    "\n",
    "def eval_weighting(w):\n",
    "    if w < -1 * high_cut:\n",
    "        return very_negative_label\n",
    "    elif w < -1 * medium_cut:\n",
    "        return negative_label\n",
    "    elif w > high_cut:\n",
    "        return very_positive_label\n",
    "    elif w > medium_cut:\n",
    "        return positive_label\n",
    "    else:\n",
    "        return neutral_label\n",
    "\n",
    "def clear_punctuation(s):\n",
    "    for e in s:\n",
    "        if e in punct:\n",
    "            s = s.replace(e, '')\n",
    "    return s\n",
    "\n",
    "def matches(s, t):\n",
    "    if s.strip().lower() == t.strip().lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_data(df, cols): # prepare comments for analysis\n",
    "    for i in cols:\n",
    "        for j in range(len(df.columns)):\n",
    "            t = df.iloc[i, j]\n",
    "            if isinstance(t, str):\n",
    "                u = clear_punctuation(t.strip().lower())\n",
    "                if matches(u, 'na'):\n",
    "                    df.iloc[i, j] = ''\n",
    "                else:\n",
    "                    df.iloc[i, j] = u\n",
    "            else:\n",
    "                df.iloc[i, j] = ''\n",
    "    return df\n",
    "\n",
    "def get_col_index(df, s): # find which column holds a string\n",
    "    for h in list(df.columns):\n",
    "        if s in h:\n",
    "            return df.columns.get_loc(h)\n",
    "\n",
    "def clean_filename(s):\n",
    "    f = ''.join(c for c in s if (c.isalnum() or c in '._- '))\n",
    "    return f\n",
    "\n",
    "def is_approving_comment(i):\n",
    "    if comment_type.index(approving) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_critical_comment(i):\n",
    "    if comment_type.index(critical) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_additional_comment(i):\n",
    "    if comment_type.index(additional) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_overlong_comment(c):\n",
    "    return (len(c.split()) > overlong)\n",
    "\n",
    "def is_lengthy_comment(c):\n",
    "    return (len(c.split()) > lengthy)\n",
    "\n",
    "def is_brief_comment(c):\n",
    "    return (len(c.split()) < brief)\n",
    "\n",
    "def is_average_length_comment(c):\n",
    "    return not (is_lengthy_comment(c) or is_brief_comment(c))\n",
    "\n",
    "def is_very_positive_comment(c, t):\n",
    "    if is_very_positive_score(get_lexical_semantic_score(c, t)):\n",
    "        return True\n",
    "    if is_very_positive_score(get_sentiment_score(c)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_negative_comment(c, t):\n",
    "    if is_very_negative_score(get_lexical_semantic_score(c, t)):\n",
    "        return True\n",
    "    if is_very_negative_score(get_sentiment_score(c)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_positive_comment(c, t):\n",
    "    if is_positive_score(get_lexical_semantic_score(c, t)):\n",
    "        return True\n",
    "    if is_positive_score(get_sentiment_score(c)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_negative_comment(c, t):\n",
    "    if is_negative_score(get_lexical_semantic_score(c, t)):\n",
    "        return True\n",
    "    if is_negative_score(get_sentiment_score(c)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_at_all_positive_comment(c, t):\n",
    "    if is_very_positive_comment(c, t):\n",
    "        return True\n",
    "    if is_positive_comment(c, t):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_at_all_negative_comment(c, t):\n",
    "    if is_very_negative_comment(c, t):\n",
    "        return True\n",
    "    if is_negative_comment(c, t):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neutral_comment(c, t):\n",
    "    for u in neut_list:\n",
    "        if matches(u, c):\n",
    "            return True\n",
    "    if is_neutral_score(get_lexical_semantic_score(c, t)):\n",
    "        return True\n",
    "    if is_neutral_score(get_sentiment_score(c)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_lexical_semantic_score(s, t): # s is the comment, t an indicator of type of comment\n",
    "    w = 0\n",
    "    for i, p in enumerate(pos_list):\n",
    "        if p in s:\n",
    "            w = min(1, w + adjustment_value * pos_weight[i] * comment_weighting[t])\n",
    "    for j, n in enumerate(neg_list):\n",
    "        if n in s:\n",
    "            w = max(-1, w - adjustment_value * neg_weight[j] * comment_weighting[t])\n",
    "    return w\n",
    "\n",
    "def get_sentiment_score(s):\n",
    "    return sii.polarity_scores(s)['compound']\n",
    "\n",
    "def get_score(s, s_):\n",
    "    if is_very_negative_comment(s, s_):\n",
    "        return very_negative_score\n",
    "    elif is_negative_comment(s, s_):\n",
    "        return negative_score\n",
    "    elif is_very_positive_comment(s, s_):\n",
    "        return very_positive_score\n",
    "    elif is_positive_comment(s, s_):\n",
    "        return positive_score\n",
    "    else:\n",
    "        return neutral_score\n",
    "\n",
    "def is_very_positive_score(s):\n",
    "    if matches(eval_weighting(s), very_positive_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_negative_score(s):\n",
    "    if matches(eval_weighting(s), very_negative_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_positive_score(s):\n",
    "    if matches(eval_weighting(s), positive_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_negative_score(s):\n",
    "    if matches(eval_weighting(s), negative_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neutral_score(s):\n",
    "    if matches(eval_weighting(s), neutral_label):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('data')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70081b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(fc.selected)\n",
    "\n",
    "cols_of_interest = []\n",
    "\n",
    "for i in range(0, len(comment_type)):\n",
    "    cols_of_interest.append(get_col_index(df, comment_type[i]))\n",
    "\n",
    "df = clean_data(df, cols_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f93991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training data\n",
    "cols_of_interest.append(get_col_index(df, 'Rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cfdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test data\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Interactions during Experience AVG'))\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Preceptor/Preceptor Team AVG'))\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Site AVG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86cd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[:, cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug number of cases\n",
    "cases = [0] * 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(c):\n",
    "\n",
    "    # consider, as needed, individually or in combination\n",
    "    #  lexical/syntactic\n",
    "    #  NL-based scores\n",
    "    #  lengths of approving, critical, and additional comments\n",
    "\n",
    "    a = ''\n",
    "    x = ''\n",
    "    d = ''\n",
    "\n",
    "    a_ = 0\n",
    "    x_ = 1\n",
    "    d_ = 2\n",
    "\n",
    "    for i in range(0, len(c)):\n",
    "        if is_approving_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                a = clear_punctuation(c[i])\n",
    "                a_ = i\n",
    "        elif is_critical_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                x = clear_punctuation(c[i])\n",
    "                x_ = i\n",
    "        elif is_additional_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                d = clear_punctuation(c[i])\n",
    "                d_ = i\n",
    "\n",
    "    j = -1\n",
    "\n",
    "    # logic provided in logic/calculate_scores.xlsm\n",
    "\n",
    "    # Case 15\n",
    "    if is_overlong_comment(x):\n",
    "        j = 15\n",
    "        r = very_negative_score\n",
    "\n",
    "    # Case 17\n",
    "    elif is_brief_comment(d) and is_very_negative_comment(d, d_):\n",
    "        j = 17\n",
    "        r = get_score(d, d_) # very_negative_score\n",
    "\n",
    "    # Case 19\n",
    "    elif is_average_length_comment(a) and (is_overlong_comment(x + d) or (is_lengthy_comment(x) and is_lengthy_comment(d))):\n",
    "        j = 19\n",
    "        r = very_negative_score\n",
    "\n",
    "    elif is_average_length_comment(a) and not is_lengthy_comment(x) and not is_lengthy_comment(d):\n",
    "\n",
    "        # Case 1\n",
    "        if is_very_positive_comment(a, a_) and not is_at_all_negative_comment(x, x_) and not is_at_all_negative_comment(d, d_):\n",
    "            j = 1\n",
    "            r = get_score(a, a_) # very_positive_score\n",
    "\n",
    "        # Case 2\n",
    "        elif is_positive_comment(a, a_) and not is_at_all_negative_comment(x, x_) and is_very_positive_comment(d, d_):\n",
    "            j = 2\n",
    "            r = get_score(d, d_) # very_positive_score\n",
    "\n",
    "        # Case 3\n",
    "        elif is_positive_comment(a, a_) and not is_at_all_negative_comment(x, x_) and not is_at_all_negative_comment(d, d_):\n",
    "            j = 3\n",
    "            r = get_score(a, a_) # positive_score\n",
    "\n",
    "        # Case 4\n",
    "        elif not is_at_all_positive_comment(a, a_) and is_very_negative_comment(x, x_) and not is_at_all_positive_comment(d, d_):\n",
    "            j = 4\n",
    "            r = get_score(x, x_) # very_negative_score\n",
    "\n",
    "        # Case 5\n",
    "        elif not is_at_all_positive_comment(a, a_) and not is_at_all_positive_comment(x, x_) and is_very_negative_comment(d, d_):\n",
    "            j = 5\n",
    "            r = get_score(d, d_) # very_negative_score\n",
    "\n",
    "        # Case 6\n",
    "        elif not is_at_all_positive_comment(a, a_) and is_negative_comment(x, x_) and is_negative_comment(d, d_):\n",
    "            j = 6\n",
    "            r = very_negative_score\n",
    "\n",
    "        # Case 7\n",
    "        elif is_at_all_positive_comment(a, a_) and is_very_negative_comment(x, x_) and is_very_negative_comment(d, d_):\n",
    "            j = 7\n",
    "            r = negative_score\n",
    "\n",
    "        # Case 8\n",
    "        elif is_positive_comment(a, a_) and is_at_all_negative_comment(x, x_) and is_at_all_negative_comment(d, d_):\n",
    "            j = 8\n",
    "            r = negative_score\n",
    "\n",
    "        # Case 9\n",
    "        elif is_at_all_positive_comment(a, a_) and is_negative_comment(x, x_) and is_at_all_positive_comment(d, d_):\n",
    "            j = 9\n",
    "            r = positive_score\n",
    "\n",
    "        # Case 10\n",
    "        elif is_neutral_comment(a, a_) and is_neutral_comment(x, x_):\n",
    "            j = 10\n",
    "            r = get_score(d, d_)\n",
    "\n",
    "        # Case 11\n",
    "        elif is_neutral_comment(a, a_) and is_at_all_negative_comment(x, x_) and is_neutral_comment(d, d_):\n",
    "            j = 11\n",
    "            r = get_score(x, x_)\n",
    "\n",
    "        # Case 12\n",
    "        elif is_very_positive_comment(a, a_) and is_negative_comment(x, x_) and is_neutral_comment(d, d_):\n",
    "            j = 12\n",
    "            r = positive_score\n",
    "\n",
    "        # Case 13\n",
    "        elif is_positive_comment(a, a_) and is_neutral_comment(x, x_) and is_very_negative_comment(d, d_):\n",
    "            j = 13\n",
    "            r = negative_score\n",
    "\n",
    "        # Case 14\n",
    "        elif is_neutral_comment(a, a_) and is_negative_comment(x, x_) and is_very_positive_comment(d, d_):\n",
    "            j = 14\n",
    "            r = positive_score\n",
    "\n",
    "        # Case 21\n",
    "        elif is_at_all_positive_comment(a, a_) and is_neutral_comment(x, x_) and is_at_all_positive_comment(d, d_):\n",
    "            j = 21\n",
    "            r = very_positive_score\n",
    "\n",
    "    elif is_lengthy_comment(x):\n",
    "\n",
    "        # Case 20\n",
    "        if is_overlong_comment(a) and not is_lengthy_comment(d):\n",
    "            j = 20\n",
    "            r = positive_score\n",
    "\n",
    "        # Case 22\n",
    "        elif is_at_all_positive_comment(a, a_) and is_neutral_comment(x, x_) and is_at_all_positive_comment(d, d_):\n",
    "            j = 22\n",
    "            r = positive_score\n",
    "\n",
    "        # Case 23\n",
    "        elif is_brief_comment(a) and is_lengthy_comment(d):\n",
    "            j = 23\n",
    "            r = negative_score\n",
    "\n",
    "        # Case 30\n",
    "        elif is_neutral_comment(a, a_) and is_at_all_negative_comment(x, x_) and is_negative_comment(d, d_):\n",
    "            j = 30\n",
    "            r = very_negative_score\n",
    "\n",
    "    # Case 18\n",
    "    elif is_lengthy_comment(a) and (is_overlong_comment(x + d) or (is_lengthy_comment(x) and is_lengthy_comment(d))):\n",
    "        j = 18\n",
    "        r = negative_score\n",
    "\n",
    "    elif is_neutral_comment(a, a_):\n",
    "\n",
    "        # Case 27\n",
    "        if is_neutral_comment(x, x_) and is_at_all_positive_comment(d, d_):\n",
    "            j = 27\n",
    "            r = get_score(d, d_)\n",
    "\n",
    "        # Case 28\n",
    "        elif is_neutral_comment(x, x_) and is_at_all_negative_comment(d, d_):\n",
    "            j = 28\n",
    "            r = get_score(d, d_)\n",
    "\n",
    "        # Case 29\n",
    "        elif is_at_all_negative_comment(x, x_) and is_neutral_comment(d, d_):\n",
    "            j = 29\n",
    "            r = get_score(x, x_)\n",
    "\n",
    "        # Case 31\n",
    "        elif is_negative_comment(x, x_) and not is_lengthy_comment(x) and is_negative_comment(d, d_):\n",
    "            j = 31\n",
    "            r = get_score(x, x_) # negative_score, or get_score(d, d_)\n",
    "\n",
    "        # Case 32\n",
    "        elif is_negative_comment(x, x_) and is_very_negative_comment(d, d_):\n",
    "            j = 32\n",
    "            r = get_score(d, d_) # very_negative_score\n",
    "\n",
    "        # Case 33\n",
    "        elif is_very_negative_comment(x, x_) and is_at_all_negative_comment(d, d_):\n",
    "            j = 33\n",
    "            r = get_score(x, x_) # very_negative_score\n",
    "\n",
    "    elif is_neutral_comment(x, x_):\n",
    "\n",
    "        # Case 24\n",
    "        elif is_negative_comment(a, a_) and is_negative_comment(d, d_):\n",
    "            j = 24\n",
    "            r = get_score(a, a_) # negative_score\n",
    "\n",
    "        # Case 25\n",
    "        elif is_at_all_positive_comment(a, a_) and is_brief_comment(x) and is_neutral_comment(d, d_):\n",
    "            j = 25\n",
    "            r = get_score(a, a_)\n",
    "\n",
    "    # Case 26\n",
    "    elif is_very_positive_comment(a, a_) and is_negative_comment(x, x_) and is_brief_comment(x) and is_at_all_positive_comment(d, d_):\n",
    "        j = 26\n",
    "        r = positive_score\n",
    "\n",
    "    # Case 16\n",
    "    elif is_overlong_comment(a) and (is_overlong_comment(x + d) or (is_lengthy_comment(x) and is_lengthy_comment(d))):\n",
    "        j = 16\n",
    "        r = neutral_score\n",
    "\n",
    "    if j < 0:\n",
    "        j = 0\n",
    "        r = neutral_score # by default\n",
    "\n",
    "    cases[j] += 1\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "evals = []\n",
    "\n",
    "for i in range(0, len(df2)): # loop for every row\n",
    "    w = calculate_score(df2.iloc[i])\n",
    "    weights.append(w)\n",
    "    evals.append(eval_weighting(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug number of cases\n",
    "print(*cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = input(\"What is the name of the output file? \")\n",
    "f = clean_filename(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test data\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Interactions during Experience AVG'))\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Preceptor/Preceptor Team AVG'))\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Site AVG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "for i in range(len(df2)):\n",
    "    if isinstance(df2.iloc[i,1], str):\n",
    "        if 'bedtime' in df2.iloc[i,1]:\n",
    "            print(get_score(df2.iloc[i,1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb406d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test data\n",
    "df2['Overall Quality'] = df.iloc[:, cols_of_interest[-3:]].sum(axis=1)\n",
    "df2[df2['Overall Quality'].eq('')] = n # may be missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea606113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Semantic Value'] = weights\n",
    "df2['Semantic Evaluation'] = evals\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active\n",
    "rows = df2r(df2, index=False)\n",
    "\n",
    "for i, row in enumerate(rows, 1):\n",
    "    for j, val in enumerate(row, 1):\n",
    "         ws.cell(row=i, column=j, value=val)\n",
    "\n",
    "wb.save('data/' + f + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddba92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
