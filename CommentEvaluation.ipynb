{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2022-2023 RENCI/ESoP, Chapel Hill, NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd437a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as sia\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows as df2r\n",
    "\n",
    "pd.options.mode.chained_assignment = None # suppress warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53200885",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words1 = pd.read_table('dictionaries/green terminology.txt', header=None)\n",
    "neg_words1 = pd.read_table('dictionaries/red terminology.txt', header=None)\n",
    "neut_words = pd.read_table('dictionaries/white terminology.txt', header=None)\n",
    "\n",
    "pos_words2 = pd.read_table('dictionaries/green terminology from literature.txt', header=None)\n",
    "neg_words2 = pd.read_table('dictionaries/red terminology from literature.txt', header=None)\n",
    "\n",
    "pos_words = pd.concat([pos_words1, pos_words2]).drop_duplicates()\n",
    "neg_words = pd.concat([neg_words1, neg_words2]).drop_duplicates()\n",
    "\n",
    "pos_list = []\n",
    "pos_weight = []\n",
    "for i in range(0, len(pos_words)):\n",
    "    if pos_words.iloc[i, 1] != 0: # ignore entries with zero weight\n",
    "        pos_list.append(pos_words.iloc[i, 0])\n",
    "        pos_weight.append(pos_words.iloc[i, 1])\n",
    "\n",
    "neg_list = []\n",
    "neg_weight = []\n",
    "for i in range(0, len(neg_words)):\n",
    "    if neg_words.iloc[i, 1] != 0:\n",
    "        neg_list.append(neg_words.iloc[i, 0])\n",
    "        neg_weight.append(neg_words.iloc[i, 1])\n",
    "\n",
    "neut_list = []\n",
    "neut_weight = 0\n",
    "for i in range(0, len(neut_words)):\n",
    "    neut_list.append(neut_words.iloc[i, 0])\n",
    "\n",
    "del pos_words\n",
    "del pos_words1\n",
    "del pos_words2\n",
    "del neg_words\n",
    "del neg_words1\n",
    "del neg_words2\n",
    "del neut_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(['names', 'stopwords', 'state_union', 'averaged_perceptron_tagger', 'vader_lexicon'], quiet=True)\n",
    "\n",
    "punct = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "sii = sia()\n",
    "\n",
    "approving = 'strengths of this experience' # literal to search in column headers\n",
    "critical = 'better learning experience'\n",
    "additional = 'Nothing further to add'\n",
    "\n",
    "comment_type = [approving, critical, additional]\n",
    "comment_weighting = [.25, .4, .35] # underweight approving comments, slightly overweight critical comments\n",
    "\n",
    "e = .001\n",
    "\n",
    "medium_cut = .05 # seems to be standard in literature for VADER compound score\n",
    "high_cut = .12 # guess at reasonable value\n",
    "adjustment_value = .03 + e # four net positive/negative statements imply high cutoff\n",
    "\n",
    "very_pos_label = 'Very positive'\n",
    "very_neg_label = 'Very negative'\n",
    "pos_label = 'Positive'\n",
    "neg_label = 'Negative'\n",
    "neut_label = 'Neutral'\n",
    "\n",
    "very_pos_score = high_cut + e\n",
    "very_neg_score = -1 * very_pos_score\n",
    "pos_score = medium_cut + e\n",
    "neg_score = -1 * pos_score\n",
    "neut_score = 0\n",
    "\n",
    "overlong = 300 # words\n",
    "lengthy = 200\n",
    "brief = 15\n",
    "\n",
    "n = numpy.nan\n",
    "nl = 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_punctuation(s):\n",
    "    for t in s:\n",
    "        if t in punct:\n",
    "            s = s.replace(t, '')\n",
    "    return s\n",
    "\n",
    "def matches(s, t):\n",
    "    if s.strip().lower() == t.strip().lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def biggest_val(l):\n",
    "    if len(l) == 0:\n",
    "        return None\n",
    "    elif len(l) == 1:\n",
    "        return l[0]\n",
    "    elif len(l) == 2:\n",
    "        if abs(l[0]) < abs(l[1]):\n",
    "            return l[1]\n",
    "        return l[0]\n",
    "    else:\n",
    "        return biggest_val([l[0], biggest_val(l[1:])])\n",
    "\n",
    "def clean_data(df, cols): # prepare comments for analysis\n",
    "    for j in cols:\n",
    "        for i in range(len(df)):\n",
    "            t = df.iloc[i, j]\n",
    "            if isinstance(t, str):\n",
    "                u = clear_punctuation(t.strip().lower())\n",
    "                if matches(u, 'na'):\n",
    "                    df.iloc[i, j] = None\n",
    "                else:\n",
    "                    df.iloc[i, j] = u\n",
    "            else:\n",
    "                df.iloc[i, j] = ''\n",
    "    return df\n",
    "\n",
    "def clean_vals(df, cols): # prepare numeric values for analysis\n",
    "    for j in cols:\n",
    "        for i in range(len(df)):\n",
    "            v = df.iloc[i, j]\n",
    "            try:\n",
    "                if v is not None:\n",
    "                    if not isinstance(v, int) and not isinstance(v, float) and not isinstance(v, complex):\n",
    "                        if isinstance(v, str):\n",
    "                            if v.isnumeric():\n",
    "                                df.iloc[i, j] = float(v)\n",
    "                            else:\n",
    "                                df.iloc[i, j] = None\n",
    "                        else:\n",
    "                            df.iloc[i, j] = None\n",
    "            except (TypeError, ValueError):\n",
    "                df.iloc[i, j] = None\n",
    "    return df\n",
    "\n",
    "def get_col_index(df, s): # find which column holds a string\n",
    "    for h in list(df.columns):\n",
    "        if s in h:\n",
    "            return df.columns.get_loc(h)\n",
    "\n",
    "def clean_filename(s):\n",
    "    f = ''.join(c for c in s.strip() if (c.isalnum() or c in '._- '))\n",
    "    return f\n",
    "\n",
    "def eval_weighting(w):\n",
    "    if w < -1 * high_cut:\n",
    "        return very_neg_label\n",
    "    elif w < -1 * medium_cut:\n",
    "        return neg_label\n",
    "    elif w > high_cut:\n",
    "        return very_pos_label\n",
    "    elif w > medium_cut:\n",
    "        return pos_label\n",
    "    else:\n",
    "        return neut_label\n",
    "\n",
    "def is_approving_comment(i):\n",
    "    if comment_type.index(approving) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_critical_comment(i):\n",
    "    if comment_type.index(critical) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_additional_comment(i):\n",
    "    if comment_type.index(additional) == i:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_overlong_comment(c):\n",
    "    return (len(c.split()) > overlong)\n",
    "\n",
    "def is_lengthy_comment(c):\n",
    "    return (len(c.split()) > lengthy)\n",
    "\n",
    "def is_brief_comment(c):\n",
    "    return (len(c.split()) < brief)\n",
    "\n",
    "def is_average_length_comment(c):\n",
    "    return not (is_lengthy_comment(c) or is_brief_comment(c))\n",
    "\n",
    "def is_very_pos_comment(c, t):\n",
    "    if is_very_pos_score(biggest_val([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_neg_comment(c, t):\n",
    "    if is_very_neg_score(biggest_val([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_pos_comment(c, t):\n",
    "    if is_pos_score(biggest_val([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neg_comment(c, t):\n",
    "    if is_neg_score(biggest_val([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_at_all_pos_comment(c, t):\n",
    "    if is_very_pos_comment(c, t):\n",
    "        return True\n",
    "    if is_pos_comment(c, t):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_at_all_neg_comment(c, t):\n",
    "    if is_very_neg_comment(c, t):\n",
    "        return True\n",
    "    if is_neg_comment(c, t):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neut_comment(c, t):\n",
    "    for u in neut_list:\n",
    "        if matches(u, c):\n",
    "            return True\n",
    "    if is_neut_score(biggest_val([get_lexical_semantic_score(c, t), get_sentiment_score(c, t)])):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_lexical_semantic_score(s, t): # s is the comment, t an indicator of type of comment\n",
    "    w = 0\n",
    "    for i, p in enumerate(pos_list):\n",
    "        if p in s:\n",
    "            w = min(1, w + adjustment_value * pos_weight[i] * comment_weighting[t])\n",
    "    for j, n in enumerate(neg_list):\n",
    "        if n in s:\n",
    "            w = max(-1, w - adjustment_value * neg_weight[j] * comment_weighting[t])\n",
    "    return w\n",
    "\n",
    "def get_sentiment_score(s, t):\n",
    "    d = .67 # temper scores as they tend to be high\n",
    "    return sii.polarity_scores(s)['compound'] * comment_weighting[t] * d\n",
    "\n",
    "def get_score(s, s_):\n",
    "    if is_very_neg_comment(s, s_):\n",
    "        return very_neg_score\n",
    "    elif is_neg_comment(s, s_):\n",
    "        return neg_score\n",
    "    elif is_very_pos_comment(s, s_):\n",
    "        return very_pos_score\n",
    "    elif is_pos_comment(s, s_):\n",
    "        return pos_score\n",
    "    else:\n",
    "        return neut_score\n",
    "\n",
    "def is_very_pos_score(s):\n",
    "    if matches(eval_weighting(s), very_pos_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_very_neg_score(s):\n",
    "    if matches(eval_weighting(s), very_neg_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_pos_score(s):\n",
    "    if matches(eval_weighting(s), pos_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neg_score(s):\n",
    "    if matches(eval_weighting(s), neg_label):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_neut_score(s):\n",
    "    if matches(eval_weighting(s), neut_label):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('data')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70081b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(fc.selected)\n",
    "\n",
    "cols_of_interest = []\n",
    "\n",
    "for i in range(0, len(comment_type)):\n",
    "    cols_of_interest.append(get_col_index(df, comment_type[i]))\n",
    "\n",
    "df = clean_data(df, cols_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f93991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training data\n",
    "cols_of_interest.append(get_col_index(df, 'Rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cfdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test data\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Interactions during Experience AVG'))\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Preceptor/Preceptor Team AVG'))\n",
    "cols_of_interest.append(get_col_index(df, 'Quality of Site AVG'))\n",
    "df = clean_vals(df, cols_of_interest[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86cd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[:, cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug counts of cases\n",
    "cases = []\n",
    "counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(c):\n",
    "\n",
    "    # consider, as needed, individually or in combination\n",
    "    #  lexical/syntactic\n",
    "    #  NL-based scores\n",
    "    #  lengths of approving, critical, and additional comments\n",
    "\n",
    "    a = ''\n",
    "    x = ''\n",
    "    d = ''\n",
    "\n",
    "    a_ = 0\n",
    "    x_ = 1\n",
    "    d_ = 2\n",
    "\n",
    "    al = []\n",
    "    xl = []\n",
    "    dl = []\n",
    "\n",
    "    for i in range(0, len(c)):\n",
    "        if is_approving_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                a = clear_punctuation(c[i])\n",
    "                a_ = i\n",
    "                al.append(get_lexical_semantic_score(a, a_))\n",
    "                al.append(get_sentiment_score(a, a_))\n",
    "        elif is_critical_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                x = clear_punctuation(c[i])\n",
    "                x_ = i\n",
    "                xl.append(get_lexical_semantic_score(x, x_))\n",
    "                xl.append(get_sentiment_score(x, x_))\n",
    "        elif is_additional_comment(i):\n",
    "            if isinstance(c[i], str):\n",
    "                d = clear_punctuation(c[i])\n",
    "                d_ = i\n",
    "                dl.append(get_lexical_semantic_score(d, d_))\n",
    "                dl.append(get_sentiment_score(d, d_))\n",
    "\n",
    "    j = nl\n",
    "\n",
    "    # logic explained in logic/calculate_scores.xlsm\n",
    "\n",
    "    if is_overlong_comment(x) and is_at_all_neg_comment(x, x_):\n",
    "        j = 'n01'\n",
    "        r = very_neg_score\n",
    "\n",
    "    elif is_brief_comment(d) and is_very_neg_comment(d, d_):\n",
    "        j = 'n02'\n",
    "        r = get_score(d, d_) # very_neg_score\n",
    "\n",
    "    elif is_average_length_comment(a) and (is_overlong_comment(x + d) or (is_lengthy_comment(x) and is_lengthy_comment(d))) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n03'\n",
    "        r = very_neg_score\n",
    "\n",
    "    elif is_neut_comment(a, a_) and is_lengthy_comment(x) and is_at_all_neg_comment(x, x_) and is_neg_comment(d, d_):\n",
    "        j = 'n04'\n",
    "        r = very_neg_score\n",
    "\n",
    "    elif not is_brief_comment(a) and is_overlong_comment(x) and not is_lengthy_comment(d):\n",
    "        j = 'n05'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_brief_comment(a) and is_lengthy_comment(x) and is_lengthy_comment(d):\n",
    "        j = 'n06'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and is_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n07'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and (is_overlong_comment(x + d) or (is_lengthy_comment(x) and is_lengthy_comment(d))):\n",
    "        j = 'n08'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_pos_comment(a, a_) and is_brief_comment(a) and is_very_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n09'\n",
    "        r = get_score(d, d_) # very_neg_score or neg_score\n",
    "\n",
    "    elif not is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n10'\n",
    "        r = get_score(d, d_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_neut_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "        j = 'n11'\n",
    "        r = get_score(d, d_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and not is_at_all_pos_comment(d, d_):\n",
    "        j = 'n12'\n",
    "        r = get_score(x, x_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_at_all_neg_comment(a, a_) and (is_at_all_neg_comment(x, x_) or is_at_all_neg_comment(d, d_)):\n",
    "        j = 'n13'\n",
    "        r = get_score(a, a_) # very_neg_score or neg_score\n",
    "\n",
    "    elif is_neg_comment(a, a_) and (is_overlong_comment(a) or is_lengthy_comment(a)) and is_neut_comment(x, x_):\n",
    "        j = 'n14'\n",
    "        r = neg_score\n",
    "\n",
    "    elif is_brief_comment(x) and is_very_pos_comment(x, x_):\n",
    "        j = 'p02'\n",
    "        r = get_score(x, x_) # very_pos_score\n",
    "\n",
    "    elif is_average_length_comment(x) and (is_overlong_comment(a + d) or (is_lengthy_comment(a) and is_lengthy_comment(d))) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p03'\n",
    "        r = very_pos_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_pos_comment(d, d_):\n",
    "        j = 'p04'\n",
    "        r = very_pos_score\n",
    "\n",
    "    elif is_overlong_comment(a) and not is_brief_comment(x) and not is_lengthy_comment(d):\n",
    "        j = 'p05'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_lengthy_comment(a) and is_brief_comment(x) and is_lengthy_comment(d):\n",
    "        j = 'p06'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_at_all_pos_comment(a, a_) and is_lengthy_comment(x) and is_neut_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p07'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_lengthy_comment(x) and (is_overlong_comment(a + d) or (is_lengthy_comment(a) and is_lengthy_comment(d))):\n",
    "        j = 'p08'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_very_pos_comment(a, a_) and is_neg_comment(x, x_) and is_brief_comment(x) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p09'\n",
    "        r = get_score(d, d_) # very_pos_score or pos_score\n",
    "\n",
    "    elif not is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p10'\n",
    "        r = get_score(d, d_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_neut_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "        j = 'p11'\n",
    "        r = get_score(d, d_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and not is_at_all_neg_comment(d, d_):\n",
    "        j = 'p12'\n",
    "        r = get_score(a, a_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_at_all_pos_comment(x, x_) and (is_at_all_pos_comment(a, a_) or is_at_all_pos_comment(d, d_)):\n",
    "        j = 'p13'\n",
    "        r = get_score(x, x_) # very_pos_score or pos_score\n",
    "\n",
    "    elif is_pos_comment(x, x_) and (is_overlong_comment(x) or is_lengthy_comment(x)) and is_neut_comment(a, a_):\n",
    "        j = 'p14'\n",
    "        r = pos_score\n",
    "\n",
    "    elif is_average_length_comment(a) and not is_lengthy_comment(x) and not is_lengthy_comment(d):\n",
    "\n",
    "        if not is_at_all_pos_comment(a, a_) and is_very_neg_comment(x, x_) and not is_at_all_pos_comment(d, d_):\n",
    "            j = 'n15'\n",
    "            r = get_score(x, x_) # very_neg_score\n",
    "\n",
    "        elif not is_at_all_pos_comment(a, a_) and is_neg_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n16'\n",
    "            r = get_score(d, d_) # very_neg_score\n",
    "\n",
    "        elif not is_at_all_pos_comment(a, a_) and not is_at_all_pos_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n17'\n",
    "            r = get_score(d, d_) # very_neg_score\n",
    "\n",
    "        elif is_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "            j = 'n18'\n",
    "            r = very_neg_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_very_neg_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n19'\n",
    "            r = neg_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_at_all_neg_comment(d, d_):\n",
    "            j = 'n20'\n",
    "            r = neg_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and is_neut_comment(x, x_) and is_very_neg_comment(d, d_):\n",
    "            j = 'n21'\n",
    "            r = neg_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and is_very_neg_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'n22'\n",
    "            r = neg_score\n",
    "\n",
    "        elif not is_at_all_pos_comment(a, a_) and is_neg_comment(x, x_) and not is_at_all_pos_comment(d, d_):\n",
    "            j = 'n23'\n",
    "            r = get_score(x, x_) # neg_score\n",
    "\n",
    "        elif is_neut_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'n24'\n",
    "            r = get_score(x, x_) # very_neg_score or neg_score\n",
    "\n",
    "        elif is_very_pos_comment(a, a_) and not is_at_all_neg_comment(x, x_) and not is_at_all_neg_comment(d, d_):\n",
    "            j = 'p15'\n",
    "            r = get_score(a, a_) # very_pos_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p16'\n",
    "            r = get_score(d, d_) # very_pos_score\n",
    "\n",
    "        elif not is_at_all_neg_comment(a, a_) and not is_at_all_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p17'\n",
    "            r = get_score(d, d_) # very_pos_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "            j = 'p18'\n",
    "            r = very_pos_score\n",
    "\n",
    "        elif is_very_pos_comment(a, a_) and is_at_all_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p19'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_neg_comment(x, x_) and is_at_all_pos_comment(d, d_):\n",
    "            j = 'p20'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_neut_comment(a, a_) and is_neg_comment(x, x_) and is_very_pos_comment(d, d_):\n",
    "            j = 'p21'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_very_pos_comment(a, a_) and is_neg_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'p22'\n",
    "            r = pos_score\n",
    "\n",
    "        elif is_pos_comment(a, a_) and not is_at_all_neg_comment(x, x_) and not is_at_all_neg_comment(d, d_):\n",
    "            j = 'p23'\n",
    "            r = get_score(a, a_) # pos_score\n",
    "\n",
    "        elif is_at_all_pos_comment(a, a_) and is_neut_comment(x, x_) and is_neut_comment(d, d_):\n",
    "            j = 'p24'\n",
    "            r = get_score(a, a_) # very_pos_score or pos_score\n",
    "\n",
    "        elif is_neut_comment(a, a_) and is_neut_comment(x, x_):\n",
    "            j = '_99'\n",
    "            r = get_score(d, d_)\n",
    "\n",
    "    if matches(j, nl):\n",
    "        j = '_00'\n",
    "        r = neut_score # by default\n",
    "\n",
    "    if cases == []:\n",
    "        cases.append(j)\n",
    "        counts.append(1)\n",
    "    elif j in cases:\n",
    "        counts[cases.index(j)] += 1\n",
    "    else:\n",
    "        cases.append(j)\n",
    "        counts.append(1)\n",
    "\n",
    "    return [r, biggest_val(al), biggest_val(xl), biggest_val(dl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "evals = []\n",
    "all_vals = []\n",
    "\n",
    "for i in range(0, len(df2)): # loop for every row\n",
    "    s = calculate_score(df2.iloc[i])\n",
    "    vals.append(s[0])\n",
    "    evals.append(eval_weighting(s[0])) # overall very negative, negative, neutral, positive, or very positive\n",
    "    all_vals.append(s[1:]) # calcs for all comment types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug counts of cases\n",
    "\n",
    "assignments = []\n",
    "\n",
    "for i, j in enumerate(cases):\n",
    "    assignments.append(j + ': ' + str(counts[i]))\n",
    "\n",
    "print(assignments)\n",
    "\n",
    "del cases\n",
    "del counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = input('What is the name of the output file? ')\n",
    "f = clean_filename(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb406d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test data\n",
    "df2['Overall Quality'] = df.iloc[:, cols_of_interest[-3:]].mean(axis=1, skipna=True)\n",
    "df2[df2['Overall Quality'].eq('')] = n # may be missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea606113",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(comment_type)):\n",
    "    df2['Lexical/Semantic Valuation--' + comment_type[i].lower()] = [v[i] for v in all_vals]\n",
    "\n",
    "df2['Overall Valuation'] = vals\n",
    "df2['Overall Evaluation'] = evals\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "rows = df2r(df2, index=False)\n",
    "\n",
    "for i, row in enumerate(rows, 1):\n",
    "    for j, val in enumerate(row, 1):\n",
    "         wb.active.cell(row=i, column=j, value=val)\n",
    "\n",
    "wb.save('data/' + f + '.xlsx')\n",
    "\n",
    "del rows\n",
    "del wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc37ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
